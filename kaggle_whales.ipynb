{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle-whales.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdoteof/neuralnet_stuff/blob/master/kaggle_whales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1O5XN1t5cpsG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Install fast.ai dependencies.  \n",
        "\n",
        "Here you want to make sure you have the gpu runtime selected.\n",
        "\n",
        "![alt text](https://i.imgur.com/tCvtjwC.png)\n",
        "\n",
        "The below will download and run a script to install fast.ai dependencies."
      ]
    },
    {
      "metadata": {
        "id": "mRNbgbD5a4dD",
        "colab_type": "code",
        "outputId": "38f176e3-ab70-4d24-f09e-69323d954fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1801
        }
      },
      "cell_type": "code",
      "source": [
        "  !curl https://course-v3.fast.ai/setup/colab | bash"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   665  100   665    0     0   3166      0 --:--:-- --:--:-- --:--:--  3151\n",
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-4.1.1\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Collecting torch_nightly\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu92/torch_nightly-1.0.0.dev20181206-cp36-cp36m-linux_x86_64.whl (576.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 576.2MB 27kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x63308000 @  0x7ff95fa492a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch-nightly\n",
            "Successfully installed torch-nightly-1.0.0.dev20181206\n",
            "Cloning into 'course-v3'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 2592 (delta 0), reused 4 (delta 0), pack-reused 2583\u001b[K\n",
            "Receiving objects: 100% (2592/2592), 79.20 MiB | 27.43 MiB/s, done.\n",
            "Resolving deltas: 100% (1406/1406), done.\n",
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/fe/4bdade529c7e0659ae2a0e4148a0e780266e127a3758ba5505d419652377/fastai-1.0.36.post1-py3-none-any.whl (140kB)\n",
            "\u001b[K    100% |████████████████████████████████| 143kB 7.1MB/s \n",
            "\u001b[?25hCollecting torchvision (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cymem==2.0.2 in /usr/local/lib/python3.6/dist-packages (from fastai) (2.0.2)\n",
            "Collecting numexpr (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: typing in /usr/local/lib/python3.6/dist-packages (from fastai) (3.6.6)\n",
            "Collecting torch (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 29kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x60d76000 @  0x7f1eb18d42a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting fastprogress>=0.1.18 (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/78/57/24a5e20f4a357f7f1c90dd5250071951c832b2480fd4fefd7be48edf4180/fastprogress-0.1.18-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Collecting dataclasses; python_version < \"3.7\" (from fastai)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.0)\n",
            "Collecting spacy==2.0.16 (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/39/288640f591b29aac6996c97ddfafc3262ae0be7513e06bc560921b112d7c/spacy-2.0.16-cp36-cp36m-manylinux1_x86_64.whl (23.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.3MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (2.1.2)\n",
            "Collecting thinc==6.12.0 (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/18/e320bfc57c20df39cc5ffa1915c7b5402a9038f290ddd85b5b72689bd57a/thinc-6.12.0-cp36-cp36m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.9MB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.14.6)\n",
            "Collecting bottleneck (from fastai)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from fastai) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.0.16->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2018.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc==6.12.0->fastai) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc==6.12.0->fastai) (0.9.0)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
            "Successfully built bottleneck\n",
            "\u001b[31mspacy 2.0.16 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, numexpr, fastprogress, dataclasses, thinc, spacy, bottleneck, fastai\n",
            "  Found existing installation: thinc 6.12.1\n",
            "    Uninstalling thinc-6.12.1:\n",
            "      Successfully uninstalled thinc-6.12.1\n",
            "  Found existing installation: spacy 2.0.18\n",
            "    Uninstalling spacy-2.0.18:\n",
            "      Successfully uninstalled spacy-2.0.18\n",
            "Successfully installed bottleneck-1.2.1 dataclasses-0.6 fastai-1.0.36.post1 fastprogress-0.1.18 numexpr-2.6.8 spacy-2.0.16 thinc-6.12.0 torch-1.0.0 torchvision-0.2.1\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CeYFBacCbHNz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from fastai import *\n",
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_EeMKWr6d1x2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Check GPU\n",
        "\n",
        "The following should output:\n",
        "\n",
        "\n",
        "```\n",
        "1.0.0\n",
        "True\n",
        "True```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qlq42S8HcdH7",
        "colab_type": "code",
        "outputId": "a7a314b3-3f91-46f6-afb1-aab722011bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.backends.cudnn.enabled)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1ac3a1e2ffc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XniXyMb_eHfl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###(Optional) Connect Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "Kq0gbJ90fE7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Go the the URL, give permissions on your google account, and copy the code in the box that is presented when you run the following code."
      ]
    },
    {
      "metadata": {
        "id": "pgVcCN3ocgdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9x93aHqofgc3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Download data from Kaggle"
      ]
    },
    {
      "metadata": {
        "id": "qIywkRzNqHcb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generate an API Token from Kaggle.  They will give you a file called kaggle.json.  Inside that file there are two values you need to fill in for `KAGGLE_USERNAME` and `KAGGLE_KEY`"
      ]
    },
    {
      "metadata": {
        "id": "IGVo4knrm6mF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!KAGGLE_USERNAME=gdoteof KAGGLE_KEY=1xxxxxxxxxxxxxxxxxxxxxxxxxx2 kaggle competitions download -c humpback-whale-identification\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4ZLmhsIm8pN",
        "colab_type": "code",
        "outputId": "0dea89ed-a925-4c29-8a07-b2059d25c14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " {BASE}\t\t       data\t\t\t        updatestatus\n",
            " clouderizer\t       drive\t\t\t        updatestatus.1\n",
            " clouderizer_init.sh   install_clouderizer_service.sh   updatestatus.2\n",
            " clouderizer.jar       kaggle.json\t\t        updatestatus.3\n",
            " clouderizer.service   models\t\t\t        updatestatus.4\n",
            " colab_init.sh\t      'My Drive'\t\t        updatestatus.5\n",
            " colab.py\t       __pycache__\n",
            " course-v3\t       sample_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S516PntYqh7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Alright, now let's move it all to our google drive.  "
      ]
    },
    {
      "metadata": {
        "id": "SIi5_e0bq34I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BASE = \"/content/drive/My Drive/ai/whales\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D80DTvYbm98f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p \"{BASE}/train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVXLlFl4qwLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv test.zip train.zip train.csv \"{BASE}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDuwuJCsrA4Y",
        "colab_type": "code",
        "outputId": "7f8889fb-b10e-481b-98ee-c8b8161fc7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!echo {BASE}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/My Drive/ai/whales\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "boKzrgswrH9i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip \"{BASE}\"/train.zip -d \"{BASE}/train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3eHEI_XgtfHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p \"{BASE}/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msJMG9WLtnPi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip \"{BASE}\"/test.zip -d \"{BASE}/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87E0fYyCuJtM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Build our databunch!"
      ]
    },
    {
      "metadata": {
        "id": "tvBTpoEZuQD7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First we set up some meta-parameters (size of the input image to the net and the batch size)"
      ]
    },
    {
      "metadata": {
        "id": "LnrFKLLVtqvg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sz=128\n",
        "bs=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aezKwFK9uXsu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = get_transforms(max_rotate=20, max_zoom=1.3, max_lighting=0.4, max_warp=0.4, p_affine=1., p_lighting=1.)\n",
        "data = ImageDataBunch.from_csv(path=BASE, folder=f'train', csv_labels=\"train.csv\", ds_tfms=tfms, sz=sz, bs=bs, size=sz, xtra_tfms=[rand_resize_crop(sz)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GBtyX76upe5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data.show_batch(rows=1, figsize=(7,6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qfhCormkuvXH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = create_cnn(data, models.resnet34, metrics=error_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vULiUTDBCQue",
        "colab_type": "code",
        "outputId": "76ec2aa5-19e2-4114-d826-a22c5f1ffec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Total time: 1:33:40 <p><table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>error_rate</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>6.889802</th>\n",
              "    <th>4.779778</th>\n",
              "    <th>0.512027</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>2</th>\n",
              "    <th>5.771892</th>\n",
              "    <th>4.577703</th>\n",
              "    <th>0.509464</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>3</th>\n",
              "    <th>5.427714</th>\n",
              "    <th>4.461701</th>\n",
              "    <th>0.506506</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>4</th>\n",
              "    <th>5.229397</th>\n",
              "    <th>4.434260</th>\n",
              "    <th>0.506309</th>\n",
              "  </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jV51TvHREe8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('whale-checkpoint')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2bh5rJW_FSId",
        "colab_type": "code",
        "outputId": "ccfc9ea7-5c07-4d83-e373-b3d90bf871c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='4', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      25.00% [1/4 12:19<36:57]\n",
              "    </div>\n",
              "    \n",
              "<table style='width:300px; margin-bottom:10px'>\n",
              "  <tr>\n",
              "    <th>epoch</th>\n",
              "    <th>train_loss</th>\n",
              "    <th>valid_loss</th>\n",
              "    <th>error_rate</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <th>1</th>\n",
              "    <th>5.213348</th>\n",
              "    <th>4.353013</th>\n",
              "    <th>0.505915</th>\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='158', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      10.13% [16/158 01:01<09:02 5.1378]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HkWSyEWkaLzX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('whale-checkpoin2')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}